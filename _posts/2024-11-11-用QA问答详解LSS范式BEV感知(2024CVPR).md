# 用QA问答详解LSS范式BEV感知

---

---

layout: post
title: "用QA问答详解LSS范式BEV感知  "
date: 2024-11-06
tags: [Perception]
comments: true
author: zihaosoog

---

## Q：LSS范式的BEV感知思路和逻辑是什么

常规LSS范式思路是：预测2D feat和depth进行点积获得2.5D的视锥feat，然后通过相机内外参数转换为3D feat，通过voxel pooling将3D feat转换到BEV feat。

## Q：如何解决LSS范式中voxel pooling带来的目标定位误差[BEVSpread]

常规的voxel pooling是将落在某个BEV grid中的所有point的3D feat相加add，但 根据是否落入某个grid的 位置近似会带来误差。

为了解决这个问题，提出分散体素池化(spread voxel pooling)，将参与计算该grid的BEV feat的point选取范围从 方形grid内 变为 圆形k近邻。具体来说，原来只add该grid内的point feat，现在将 distance(grid中心点, point)以及depth 作为加权的weight，选取圆形范围内k近邻point feat 作 weighted add。

需要CUDA算子加速，一定程度上不利于模型快速推理，加大了部署难度。

## Q：如何通过CRF和分组时序融合提升LSS范式中depth和temporal性能[BEVNeXT]

多相机的6v img作为输入图像，通过backbone和neck提取多尺度2D feat(s4/s8/s16/s32)。

depth预测添加CRF约束，通过颜色平滑度先验来增强depth一致性。基础的depthnet采用分割的方式完成离散深度值的分类预测，CRF通过约束两个像素点的 图像块平均RGB像素值差异I 和 dpeth差异x 作为 代价函数。2D feat和depth通过view transformer得到BEV feat。

$\psi_p(x_i, x_j) = \sum_{w} w \exp \left( -\frac{|I_i - I_j|^2}{2\theta^2} \right) |x_i - x_j|$

时序帧输入共k帧(t-k, t)，分为g组，分组方式类似于k个人一字排开轮流报数，如1/2/k/1/2/k…，报相同数字的人为同一组。对于第j组内feat通过cat然后conv得到feat_j，其次完成组间相加，即feat_j(current feat)和feat_j+1进行add然后conv得到feat‘_j+1，对所有的 feat’_i(0<i<g)分别进行多尺度conv特征提取，最后cat所有feat’_i然后conv，实现时序的current分组融合。